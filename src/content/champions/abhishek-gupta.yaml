firstName: Abhishek
lastName: Gupta
role: Chair, Standards Working Group (GSF)
organization: Green Software Foundation
languages: 
  - English
  - French
  - Hindi
pronoun: He/Him
country: Canada
city: Montreal
bio: |
 Abhishek Gupta is the Director for Responsible AI with the Boston Consulting Group (BCG) where he works with BCG's Chief AI Ethics Officer to advise clients and build end-to-end Responsible AI programs. He is also the Founder & Principal Researcher at the Montreal AI Ethics Institute (https://montrealethics.ai ), an international non-profit research institute with a mission to democratize AI ethics literacy. Through his work as the Chair of the Standards Working Group at the Green Software Foundation, he is leading the development of a Software Carbon Intensity standard towards the comparable and interoperable measurement of the environmental impacts of AI systems.
 His work focuses on applied technical, policy, and organizational measures for building ethical, safe, and inclusive AI systems and organizations, specializing in the operationalization of Responsible AI and its deployments in organizations and assessing and mitigating the environmental impact of these systems. He has advised national governments, multilateral organizations, academic institutions, and corporations across the globe. His work on community building has been recognized by governments from across North America, Europe, Asia, and Oceania. He is a highly sought after speaker with talks at the United Nations, European Parliament, G7 AI Summit, TEDx, Harvard Business School, Kellogg School of Management, amongst others. His writing on Responsible AI has been featured by Wall Street Journal, Forbes, MIT Technology Review, Protocol, Fortune, VentureBeat, amongst others. 
 He is an alumnus of the US State Department International Visitors Leadership Program representing Canada and has received The Gradient Writing Prize 2021 for his work on The Imperative for Sustainable AI Systems. His research has been published in leading AI journals and presented at top-tier ML conferences like NeurIPS, ICML, and IJCAI. He is the author of the widely-read State of AI Ethics Report (https://montrealethics.ai/state ) and The AI Ethics Brief (https://brief.montrealethics.ai ). He formerly worked at Microsoft as a Machine Learning Engineer in Commercial Software Engineering (CSE) where his team helped to solve the toughest technical challenges faced by Microsoft's biggest customers. He also served on the CSE Responsible AI Board at Microsoft. You can learn more about his work here - https://abhishek-gupta.ca 
type: normal
social:
  github: atg-abhishek
  linkedin: abhishekguptamcgill
  twitter: atg_abhishek
  website: https://abhishek-gupta.ca
activities:
  - contributionType: writing
    linkedGSFProject: Green Software Practitioner (Principles)
    subtype: company-article
    dateFrom: 2022-11-08
    dateTo: 2022-11-08
    title: Why Your Organization Needs Sustainable Software
    description: Your digital infrastructure probably generates more carbon emissions than you think—and AI may make it worse. It’s time for sustainable software.
    url: https://www.bcg.com/publications/2022/why-your-organization-needs-sustainable-software
    relatedEvent: Boston Consulting Group (BCG)
  - contributionType: writing
    linkedGSFProject: Community WG
    subtype: 3rd-party-article
    dateFrom: 2021-09-18
    dateTo: 2021-09-18
    title: The Imperative for Sustainable AI Systems
    description: "AI systems are compute-intensive: the AI lifecycle often requires long-running training jobs, hyperparameter searches, inference jobs, and other costly computations. They also require massive amounts of data that might be moved over the wire, and require specialized hardware to operate effectively, especially large-scale AI systems. All of these activities require electricity — which has a carbon cost. There are also carbon emissions in ancillary needs like hardware and datacenter cooling."
    url: https://thegradient.pub/sustainable-ai
    relatedEvent: The Gradient
  - contributionType: speaking
    linkedGSFProject: Community WG
    subtype: online-talk
    dateFrom: 2021-08-20
    dateTo: 2021-08-20
    title: The Launch Space – A roadmap to more sustainable AI systems
    description: AI has a sizeable carbon footprint, both during training and deployment phases. How do we build AI systems that are greener? The first thing we need to understand is how to account and calculate the carbon impact of all the resources that go into the AI lifecycle. So what is the current state of carbon accounting in AI? How effective has it been? And can we do better? This conversation will answer these questions and dive into what the future of carbon accounting in AI looks like and what role standards can play in this, especially if we want to utilize actionable insights to trigger meaningful behavior change.
    url: https://www.youtube.com/watch?v=wIC2Za8hHuE&ab_channel=MicrosoftDeveloper
    relatedEvent: The Launch Space
  - contributionType: writing
    linkedGSFProject: Community WG
    subtype: 3rd-party-article
    dateFrom: 2021-06-25
    dateTo: 2021-06-25
    title: A Social and Environmental Certificate for AI Systems
    description: As more countries realize the potential AI has to offer in terms of economic opportunities, large societal problems have also been lumped under the category of things that can be “solved” using AI. This is reflected in the national AI strategies of various countries1 where grandiose claims are made that if only we throw enough computation, data, and the pixie dust of AI on it, we will be able to solve, among other things, the climate crises that looms large over our heads.
     AI systems are not without their flaws. There are many ethical issues to consider when thinking about deploying AI systems into society—particularly environmental impacts3. 
     Of course, readers of this publication are no strangers to such grandiose claims every time there is a new policy or technical instrument2 that is proposed and ends up falling short of meaningfully addressing the climate crisis. There is no silver bullet! 
    url: https://branch.climateaction.tech/issues/issue-2/secure-framework/
    relatedEvent: Branch Magazine
  - contributionType: writing
    linkedGSFProject: Community WG
    subtype: company-article
    dateFrom: 2021-06-07
    dateTo: 2021-06-07
    title: The current state of affairs and a roadmap for effective carbon-accounting tooling in AI
    description: Digital services consume a lot of energy and it goes without saying that in a world with accelerating climate change, we must be conscious in all parts of life with our carbon footprints. In the case of the software that we write, specifically, the AI systems we build, these considerations become even more important because of the large upfront computational resources that training some large AI models consume, and the subsequent carbon emissions resulting from it. Thus, effective carbon accounting for artificial intelligence systems is critical!
    url: https://devblogs.microsoft.com/sustainable-software/the-current-state-of-affairs-and-a-roadmap-for-effective-carbon-accounting-tooling-in-ai/
    relatedEvent: Microsoft Dev Blogs
  - contributionType: writing
    linkedGSFProject: Community WG
    subtype: 3rd-party-article
    dateFrom: 2020-06-11
    dateTo: 2020-06-11
    title: "SECure: A Social and Environmental Certificate for AI Systems"
    description: "In a world increasingly dominated by AI applications, an understudied aspect is the carbon and social footprint of these power-hungry algorithms that require copious computation and a trove of data for training and prediction. While profitable in the short-term, these practices are unsustainable and socially extractive from both a data-use and energy-use perspective. This work proposes an ESG-inspired framework combining socio-technical measures to build eco-socially responsible AI systems. The framework has four pillars: compute-efficient machine learning, federated learning, data sovereignty, and a LEEDesque certificate.
     Compute-efficient machine learning is the use of compressed network architectures that show marginal decreases in accuracy. Federated learning augments the first pillar's impact through the use of techniques that distribute computational loads across idle capacity on devices. This is paired with the third pillar of data sovereignty to ensure the privacy of user data via techniques like use-based privacy and differential privacy. The final pillar ties all these factors together and certifies products and services in a standardized manner on their environmental and social impacts, allowing consumers to align their purchase with their values."
    url: https://arxiv.org/abs/2006.06217
    relatedEvent: arXiv